{
    "caption": "AI Inference",
    "description": "Adds latency, model info, token usage, and endpoints to inference events.",
    "meta": "profile",
    "name": "ai_inference",
    "annotations": {
      "group": "primary"
    },
    "attributes": {
        "model_name": {
            "caption": "Model Name",
            "description": "Name of the AI model used in inference (e.g., gpt-4, bert-large, llama-2).",
            "group": "primary",
            "requirement": "recommended"
        },
        "model_version": {
            "caption": "Model Version",
            "description": "Version of the deployed model, which may include release date or custom tag.",
            "group": "primary",
            "requirement": "recommended"
        },
        "model_owner": {
            "caption": "Model Owner",
            "description": "Entity or organization responsible for the model (e.g., OpenAI, Internal).",
            "group": "primary",
            "requirement": "recommended"
        },
        "deployment_id": {
            "caption": "Deployment ID",
            "description": "Identifier of the deployed model instance, useful for tracing across environments.",
            "group": "primary",
            "requirement": "recommended"
        },
        "input_signature": {
            "caption": "Input Signature",
            "description": "A fingerprint or schema representation of the input structure for this inference.",
            "group": "context",
            "requirement": "optional"
        },
        "output_type": {
            "caption": "Output Type",
            "description": "Format or semantic type of the inference output (e.g., text, classification_label, image).",
            "group": "context",
            "requirement": "optional"
        },
        "confidence_score": {
            "caption": "Confidence Score",
            "description": "Confidence value indicating prediction certainty.",
            "group": "context",
            "requirement": "optional"
        },
        "latency_ms": {
            "caption": "Latency",
            "description": "Time taken to complete the model inference in milliseconds.",
            "group": "context",
            "requirement": "optional"
        },
        "endpoint": {
            "caption": "Endpoint",
            "description": "Endpoint or URI where the inference was executed.",
            "group": "context",
            "requirement": "optional"
        },
        "user": {
            "caption": "User",
            "description": "User, service, or process initiating the inference.",
            "group": "context",
            "requirement": "optional"
        },
        "region": {
            "caption": "Region",
            "description": "Cloud or datacenter region where the inference occurred",
            "group": "context",
            "requirement": "optional"
        },
        "trace": {
            "caption": "Trace",
            "description": "Trace object containing ID for end-to-end observability.",
            "group": "primary",
            "requirement": "recommended"
        },
        "input_tokens": {
            "caption": "Input Tokens",
            "description": "Number of tokens in the input prompt.",
            "group": "context",
            "requirement": "optional"
        },
        "output_tokens": {
            "caption": "Output Tokens",
            "description": "Number of tokens generated by the model.",
            "group": "context",
            "requirement": "optional"
        },
        "total_tokens": {
            "caption": "Total Tokens",
            "description": "Sum of input and output tokens for this inference.",
            "group": "context",
            "requirement": "optional"
        }
    }
}